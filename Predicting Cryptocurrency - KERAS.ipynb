{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7033ef11",
   "metadata": {},
   "source": [
    "# Predicting Cryptocurrency - RNN and KERAS\n",
    "Credit: sentdex YouTube Channel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8f0ef",
   "metadata": {},
   "source": [
    "Step 1: Read in Data and Name Header Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "#!pip install tensorflow\n",
    "#!pip install --upgrade tensorflow\n",
    "#!pip install keras\n",
    "#!pip install tf-nightly\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "SEQ_LEN = 60\n",
    "FUTURE_PERIOD_PREDICT = 3\n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n",
    "\n",
    "# Columns are not named, so naming when reading in\n",
    "# This is just an example of one of the files to get a feel for what it contains\n",
    "df = pd.read_csv(\"Documents/LTC-USD.csv\", names = [\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d2b2c",
   "metadata": {},
   "source": [
    "    Read in all 4 files for the different bitcoin types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc695cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"ETH-USD\", \"BCH-USD\"]\n",
    "for ratio in ratios:\n",
    "    dataset = f\"Documents/{ratio}.csv\"\n",
    "    #reading in all the data, naming columns based on which crypto \n",
    "    df = pd.read_csv(dataset, names = [\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"])\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\":f\"{ratio}_volume\"}, inplace =True)\n",
    "    # setting index to time and selecting columns of interest\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]\n",
    "    #\n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df)\n",
    "print(main_df.head())\n",
    "\n",
    "for c in main_df.columns:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e580781",
   "metadata": {},
   "source": [
    "For supervised ML - need sequences and need targets. What are the targets?\n",
    "SEQ_LEN = ?\n",
    "FUTURE_PERIOD_PREDICT = ?\n",
    "RATIO_TO_PREDICT = \"LTC-USD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should the reccomendation be to purchase or to sell, to buy = 1\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# ID the future price - where it will close - shifting close column however many periods forward I want to predict\n",
    "main_df['future'] = main_df[f\"{RATIO_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT)\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing whether the classify function works, whether to buy or not\n",
    "main_df['target'] = list(map(classify, main_df[f\"{RATIO_TO_PREDICT}_close\"],main_df[\"future\"]))\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\", \"target\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fe200",
   "metadata": {},
   "source": [
    "Step 2: Normalizing, creating sequences and balancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting index (time) - should be sorted, but this makes sure\n",
    "times = sorted(main_df.index.values)\n",
    "# taking the last 5% of the data to be used for validation\n",
    "last_5pct = times[-int(0.05*len(times))]\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "# removing the last 5% from the main df\n",
    "main_df = main_df[(main_df.index < last_5pct)]\n",
    "\n",
    "# function to set up model\n",
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1)  # don't need this anymore.\n",
    "\n",
    "    for col in df.columns:  # go through all of the columns\n",
    "        if col != \"target\":  # normalize all ... except for the target itself!\n",
    "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "            df.dropna(inplace=True)  # remove the nas created by pct_change\n",
    "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "\n",
    "    df.dropna(inplace=True)  # cleanup again... jic.\n",
    "\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "    for i in df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "\n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "\n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "\n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "\n",
    "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
    "\n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "    sequential_data = buys+sells  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X), y\n",
    "            \n",
    "        \n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9da74",
   "metadata": {},
   "source": [
    "Step 3: Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001, weight_decay=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.keras\".format(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "\n",
    "print(BATCH_SIZE)\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"models/{}\".format(NAME))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a3b03",
   "metadata": {},
   "source": [
    "64\n",
    "Epoch 1/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 473s 440ms/step - accuracy: 0.5135 - loss: 0.7601 - val_accuracy: 0.5451 - val_loss: 0.6866\n",
    "Epoch 2/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 487s 472ms/step - accuracy: 0.5374 - loss: 0.6897 - val_accuracy: 0.5696 - val_loss: 0.6820\n",
    "Epoch 3/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 489s 474ms/step - accuracy: 0.5527 - loss: 0.6858 - val_accuracy: 0.5699 - val_loss: 0.6796\n",
    "Epoch 4/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 528s 512ms/step - accuracy: 0.5635 - loss: 0.6813 - val_accuracy: 0.5636 - val_loss: 0.6782\n",
    "Epoch 5/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 718s 696ms/step - accuracy: 0.5683 - loss: 0.6789 - val_accuracy: 0.5835 - val_loss: 0.6747\n",
    "Epoch 6/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 695s 674ms/step - accuracy: 0.5769 - loss: 0.6765 - val_accuracy: 0.5778 - val_loss: 0.6745\n",
    "Epoch 7/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 399s 386ms/step - accuracy: 0.5783 - loss: 0.6755 - val_accuracy: 0.5807 - val_loss: 0.6743\n",
    "Epoch 8/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 360s 349ms/step - accuracy: 0.5796 - loss: 0.6728 - val_accuracy: 0.5627 - val_loss: 0.6797\n",
    "Epoch 9/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 369s 357ms/step - accuracy: 0.5951 - loss: 0.6662 - val_accuracy: 0.5731 - val_loss: 0.6826\n",
    "Epoch 10/10\n",
    "1031/1031 ━━━━━━━━━━━━━━━━━━━━ 363s 352ms/step - accuracy: 0.6095 - loss: 0.6574 - val_accuracy: 0.5570 - val_loss: 0.6861\n",
    "Test loss: 0.6859279870986938\n",
    "Test accuracy: 0.5570258498191833"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
